{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vd8K04Eyb4eL"
      },
      "outputs": [],
      "source": [
        "!pip install qalsadi\n",
        "!pip install tensorflow\n",
        "!pip install emoji\n",
        "!pip install sklearn\n",
        "!pip install nlpaug\n",
        "!pip install textattack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVb5gylfdZf5"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "import qalsadi.lemmatizer\n",
        "from nltk.stem.isri import ISRIStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
        "from types import new_class\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "import emoji\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import arabicstopwords.arabicstopwords as stp\n",
        "import string\n",
        "from nltk.stem.porter import *\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.utils import resample\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "# import nlpaug.augmenter.word as naw\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "from textattack.augmentation import Augmenter, WordNetAugmenter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0Vl1EMnRaFN"
      },
      "outputs": [],
      "source": [
        "def tokenization(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7E_a9IPRiRs"
      },
      "outputs": [],
      "source": [
        "def remove_punctuation(text):\n",
        "    punctuation = ['!','\\\"','#','$','%','&','\\\\','\\'','(',')','*','+','-','.','/',':','<','>','=','؟','@','[',']',['\\\\\\\\'],'^','_','`','{','}','|','~','،','؛','÷','×']\n",
        "    punctuationfree=\"\".join([i for i in text if i not in punctuation])\n",
        "    return punctuationfree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGHVvkASShSD"
      },
      "outputs": [],
      "source": [
        "def remove_stop_words(text):\n",
        "   stopWords=list(set(stopwords.words(\"arabic\")))\n",
        "   #stopWords = list(stp.classed_stopwords_list())\n",
        "  #  for word in ['لا','لكن','ولكن']:\n",
        "  #   stopWords.remove(word)\n",
        "   added_sw = ['من','في','و','ده','ايه','حتى','ليه','انى','لكن','ان','الى','،','فقط','ايه','لما','هما','انه','ثم','هو','هى','لو','انا'\n",
        ",'انتم','هم','جدا','انتى','انت','بدون','ب','ك','ل','على','فوق','تحت','عن','مكو','هلا','اصبح','كان','مرة','بصراحة','اذا','او','زى','كل','كدة','حني','كده','أو']\n",
        "   for word in added_sw:\n",
        "    stopWords.append(word)\n",
        "\n",
        "   output= [i for i in text if i not in stopWords]\n",
        "   return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSgZJnQAV4mI"
      },
      "outputs": [],
      "source": [
        "wn_lemmatizer = WordNetLemmatizer()\n",
        "lc_stemmer = LancasterStemmer()\n",
        "sb_stemmer = SnowballStemmer(language='arabic')\n",
        "p_stemmer = PorterStemmer()\n",
        "isri_stemmer = ISRIStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QTxhHJHVK9e"
      },
      "outputs": [],
      "source": [
        "def arabic_stemmer(text):\n",
        "    stem_text = [lc_stemmer.stem(word) for word in text]\n",
        "    return stem_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lz6WMsHOWapV"
      },
      "outputs": [],
      "source": [
        "def arabic_lemmatizer(text):\n",
        "    lemma_text = [wn_lemmatizer.lemmatize(word) for word in text]\n",
        "    return lemma_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u89VLZxBaFLo"
      },
      "outputs": [],
      "source": [
        "def emojis_converter(text):\n",
        "  emoji_translations = {\n",
        "                        \":thumbs_up:\" :\" ايجابى\" ,\n",
        "                        \":angry_face:\" : \"سلبى\" ,\n",
        "                        \":hear-no-evil_monkey:\" : \" ايجابى\",\n",
        "                        \":speak-no-evil_monkey:\" : \" ايجابى\" ,\n",
        "                        \":see-no-evil_monkey:\" :\"ايجابى \" ,\n",
        "                        \":face_with_tears_of_joy:\" :\"ايجابى \" ,\n",
        "                        \":smiling_face_with_heart-eyes:\" : \"ايجابى \",\n",
        "                        \":man_facepalming_light_skin_tone:\"  : \"سلبي \" ,\n",
        "                        \":cherry_blossom:\"  : \"ايجابى \" ,\n",
        "                        \":heart_exclamation:\"  : \" ايجابى\" ,\n",
        "                        \":crossed_fingers:\"  : \" ايجابى\" ,\n",
        "                        \":purple_heart:\"  : \"ايجابى \" ,\n",
        "                        \":smiling_cat_with_heart-eyes:\" : \"ايجابى \",\n",
        "                        \":heart_suit:\" : \" ايجابى\",\n",
        "                        \":red_heart:\" : \" ايجابى\" ,\n",
        "                        \":winking_face:\" : \" ايجابى\",\n",
        "                        \":two_hearts:\" : \" ايجابى\",\n",
        "                        \":face_with_tongue:\" : \" ايجابى\",\n",
        "                        \":winking_face_with_tongue:\" : \"ايجابى \",\n",
        "                        \":persevering_face:\" : \"سلبى\" ,\n",
        "                        \":face_screaming_in_fear:\" : \"سلبى\" ,\n",
        "                        \":broken_heart:\" : \"سلبى\" ,\n",
        "                        \":blue_heart:\" : \" ايجابى\" ,\n",
        "                        \":smiling_face_with_smiling_eyes:\" : \" ايجابى\" ,\n",
        "                        \":confused_face:\" :\" سلبى\",\n",
        "                        \":beating_heart:\" :\" ايجابى\",\n",
        "                        \":Kuwait:\" : \" ايجابى\",\n",
        "                        \":smiling_face_with_sunglasses:\" : \" ايجابى\",\n",
        "                        \":black_heart:\" : \" ايجابى\",\n",
        "                        \":rose:\" :\" ايجابى\",\n",
        "                        \":kissing_face_with_closed_eyes:\" :\"ايجابى \",\n",
        "                        \":smiling_face_with_heart:\" : \" ايجابى\",\n",
        "                        \":call_me_hand:\" :\" ايجابى\",\n",
        "                        \":pensive_face:\" : \"سلبى\",\n",
        "                        \":front-facing_baby_chick:\" :\" ايجابى\",\n",
        "                        \":pinched_fingers:\" : \" سلبى\",\n",
        "                        \":growing_heart:\" : \" ايجابى\",\n",
        "                        \":OK_hand:\" :  \" ايجابى\",\n",
        "                        \":face_with_steam_from_nose:\" : \" سلبى\",\n",
        "                        \":loudly_crying_face:\" : \"سلبى\",\n",
        "                        \":tired_face:\" : \"سلبى\",\n",
        "                        \":grinning_squinting_face:\" : \"ايجابى\",\n",
        "                        \":enraged_face:\" : \"سلبى\",\n",
        "                        \":smiling_face_with_hearts:\" : \"ايجابى\",\n",
        "                        \":face_blowing_a_kiss:\" : \"ايجابى\",\n",
        "                        \":face_savoring_food:\" : \"ايجابى\",\n",
        "                        \":grinning_face_with_big_eyes:\" : \"ايجابى\",\n",
        "                        \":star:\" : \"ايجابى\",\n",
        "                        \":double_exclamation_mark:\" : \"سلبى\",\n",
        "                        \":unamused_face:\" : \"سلبى\",\n",
        "                        \":white_heart:\" : \"ايجابى\",\n",
        "                        \":hundred_points:\" : \"ايجابى\",\n",
        "                        \":cat_with_tears_of_joy:\" : \"ايجابى\",\n",
        "                        \":eyes:\" : \" ايجابى\",\n",
        "                        \":flexed_biceps:\": \" ايجابى\",\n",
        "                        \":revolving_hearts:\": \"ايجابى\",\n",
        "                        \":beaming_face_with_smiling_eyes:\": \"ايجابى\",\n",
        "                        \":pile_of_poo:\": \"سلبى\",\n",
        "                        \":grimacing_face:\": \"سلبى\",\n",
        "                        \":bouquet:\": \"ايجابى\",\n",
        "                        \":raised_fist:\": \"سلبى\",\n",
        "                        \":raised_back_of_hand:\": \"ايجابى\",\n",
        "                        \":neutral_face:\": \"سلبى\",\n",
        "                        \":clapping_hands:\": \"ايجابى\",\n",
        "                        \":tongue:\": \"سلبى\",\n",
        "                        \":thumbs_down:\": \"سلبى\",\n",
        "                        \":thumbs_up_medium_skin_tone:\": \"ايجابى\",\n",
        "                        \":downcast_face_with_sweat:\": \"سلبى\",\n",
        "                        \":crying_face:\": \"سلبى\",\n",
        "                        \":slightly_smiling_face:\": \"سلبى\",\n",
        "                        \":high_voltage:\" : \"ايجابى\",\n",
        "                        \":couple_with_heart_woman_woman:\": \"ايجابى\",\n",
        "                        \":check_mark_button:\": \"ايجابى \",\n",
        "                        \":thinking_face:\" : \" سلبى\",\n",
        "                        \":fire:\": \" ايجابى\",\n",
        "                        \":Jordan:\": \" ايجابى\",\n",
        "                        \":sad_but_relieved_face:\": \"سلبى\",\n",
        "                        \":flexed_biceps_medium-light_skin_tone:\": \"ايجابى\",\n",
        "                        \":smiling_face_with_horns:\": \"سلبى\",\n",
        "                        \":collision:\": \"ايجابى\",\n",
        "                        \":check_box_with_check:\": \"ايجابى \",\n",
        "                        \":folded_hands:\": \"ايجابى\",\n",
        "                        \":astonished_face:\": \" سلبى\",\n",
        "                        \":sparkling_heart:\": \" ايجابى\",\n",
        "                        \":smiling_face:\": \"ايجابى \",\n",
        "                        \":hot_face:\": \"ايجابى\",\n",
        "                        \":globe_showing_Europe-Africa:\": \"ايجابى\",\n",
        "                        \":smirking_face:\": \"ايجابى \",\n",
        "                        \":thumbs_up_medium-dark_skin_tone:\": \"ايجابى \",\n",
        "                        \":smiling_face_with_open_hands:\": \"ايجابى \",\n",
        "                        \":smiling_face_with_halo:\": \" ايجابى\",\n",
        "                        \":nauseated_face:\": \" سلبى\",\n",
        "                        \":face_without_mouth:\": \" سلبى\",\n",
        "                        \":OK_hand_light_skin_tone:\": \"ايجابى \",\n",
        "                        \":raised_hand:\": \" ايجابى\",\n",
        "                        \":oncoming_fist:\": \" سلبى\",\n",
        "                        \":victory_hand_medium-light_skin_tone:\": \" ايجابى\",\n",
        "                        \":man_shrugging:\": \"ايجابى\",\n",
        "                        \":man_gesturing_NO:\": \"ايجابى\",\n",
        "                        \":face_with_symbols_on_mouth:\": \" سلبى\",\n",
        "                        \":heart_with_ribbon:\": \" ايجابى\",\n",
        "                        \":gem_stone:\": \" ايجابى\",\n",
        "                        \":tulip:\": \"ايجابى \",\n",
        "                        \":orange_heart:\": \"ايجابى \",\n",
        "                        \":face_with_raised_eyebrow:\": \" سلبى\",\n",
        "                        \":expressionless_face:\": \" سلبى\",\n",
        "                        \":cherries:\":\"ايجابى\",\n",
        "                        \":kissing_face_with_smiling_eyes:\": \"ايجابى\",\n",
        "                        \":1st_place_medal:\": \"ايجابى\",\n",
        "                        \":hibiscus:\": \"ايجابى\",\n",
        "                        \":sparkles:\": \"ايجابى\",\n",
        "                        \":nerd_face:\": \"سلبى\",\n",
        "                        \":kissing_face:\": \"ايجابى\",\n",
        "                        \":woman_dancing:\": \"ايجابى\",\n",
        "                        \":yellow_heart:\": \"ايجابى\",\n",
        "                        \":grinning_face:\": \"ايجابى\",\n",
        "                        \":pleading_face:\": \"سلبى\",\n",
        "                        \":flushed_face:\": \"سلبى\",\n",
        "                        \":anguished_face:\": \"سلبى\",\n",
        "                        \":cooking:\": \"ايجابى\",\n",
        "                        \":hot_springs:\": \"ايجابى\",\n",
        "                        \":hamburger:\": \"ايجابى\",\n",
        "                        \":disappointed_face:\": \"سلبى\",\n",
        "                        \":face_with_hand_over_mouth:\": \"سلبى\",\n",
        "                        \":hushed_face:\": \"سلبى\",\n",
        "                        \":frowning_face:\": \"سلبى\",\n",
        "                        \":rolling_on_the_floor_laughing:\": \"ايجابى\",\n",
        "                        \":grinning_face_with_sweat:\" : \"ايجابى\" ,\n",
        "                        \":heart_decoration:\" : \"ايجابى\",\n",
        "                        \":face_vomiting:\" : \"سلبى\",\n",
        "                        \":star-struck:\": \"ايجابى\",\n",
        "                        \":Oman:\": \"ايجابى\",\n",
        "                        \":snowflake:\": \"ايجابى\",\n",
        "                        \":spaghetti:\": \"ايجابى\",\n",
        "                        \":stuffed_flatbread:\": \"ايجابى\",\n",
        "                        \":green_apple:\": \"ايجابى\",\n",
        "                        \":mouth:\": \"ايجابى\",\n",
        "                        \":sun_with_face:\": \"ايجابى\",\n",
        "                        \":green_heart:\": \"ايجابى\",\n",
        "                        \":zipper-mouth_face:\": \"سلبى\",\n",
        "                        \":thumbs_up_light_skin_tone:\": \"ايجابى\",\n",
        "                        \":microphone:\": \"سلبى\",\n",
        "                        \":cat_face:\": \"ايجابى\",\n",
        "                        \":backhand_index_pointing_right_medium_skin_tone:\": \"سلبى\",\n",
        "                        \":thumbs_up_medium-light_skin_tone:\": \"ايجابى\",\n",
        "                        \":zany_face:\": \"ايجابى\",\n",
        "                        \":clapping_hands_medium_skin_tone:\": \"ايجابى\",\n",
        "                        \":cross_mark:\": \"سلبى\",\n",
        "                        \":-) :\": \"ايجابى\",\n",
        "                        \":-)⁩⁦::\": \"ايجابى\",\n",
        "                        \":wilted_flower:\": \"ايجابى\",\n",
        "                        \":clown_face:\": \"سلبى\",\n",
        "                        \":zebra:\": \"ايجابى\",\n",
        "                        \":moai:\": \"سلبى\",\n",
        "                        \":woman’s_hat:\": \"ايجابى\",\n",
        "                        \":grinning_face_with_smiling_eyes:\": \"سلبى\",\n",
        "                        \":kiss_mark:\": \"ايجابى\",\n",
        "                        \":heart_with_arrow:\" : \"ايجابى\" ,\n",
        "                        \":meat_on_bone:\" : \"ايجابى\",\n",
        "                        \":poultry_leg:\": \"ايجابى\",\n",
        "                        \":cut_of_meat:\": \"ايجابى\",\n",
        "                        \":bacon:\": \"ايجابى\",\n",
        "                        \":cheese_wedge:\": \"ايجابى\",\n",
        "                        \":egg:\": \"سلبى\",\n",
        "                        \":pancakes:\": \"ايجابى\",\n",
        "                        \":sandwich:\": \"ايجابى\",\n",
        "                        \":bread:\": \"ايجابى\",\n",
        "                        \":chestnut:\": \"ايجابى\",\n",
        "                        \":red_apple:\": \"ايجابى\",\n",
        "                        \":money_with_wings:\": \"ايجابى\",\n",
        "                        \":french_fries:\": \"ايجابى\",\n",
        "                        \":ogre:\": \"سلبى\",\n",
        "                        \":K_hand_medium-light_skin_tone:\": \"ايجابى\",\n",
        "                        \":raising_hands:\": \"ايجابى\",\n",
        "                        \":new_moon_face:\": \"سلبى\",\n",
        "                        \":cross_mark_button:\": \"سلبى\",\n",
        "                        \":droplet:\": \"ايجابى\",\n",
        "                        \":herb:\": \"سلبى\",\n",
        "                        \":deciduous_tree:\": \"ايجابى\",\n",
        "                        \":leaf_fluttering_in_wind:\": \"ايجابى\",\n",
        "                        \":cloud:\" :\"ايجابى\",\n",
        "                        \":closed_umbrella:\": \"سلبى\",\n",
        "                        \":dizzy:\": \"ايجابى\",\n",
        "                        \":kissing_cat:\": \"ايجابى\",\n",
        "                        \":fried_shrimp:\": \"ايجابى\",\n",
        "                        \":sushi:\": \"ايجابى\",\n",
        "                        \":pizza:\": \"ايجابى\",\n",
        "                        \":steaming_bowl:\": \"ايجابى\",\n",
        "                        \":rice_ball:\": \"ايجابى\",\n",
        "                        \":cooked_rice:\": \"ايجابى\",\n",
        "                        \":curry_rice:\": \"ايجابى\",\n",
        "                        \":pot_of_food:\": \"ايجابى\",\n",
        "                        \":oden:\": \"ايجابى\",\n",
        "                        \":dango:\": \"ايجابى\",\n",
        "                        \":bento_box:\": \"ايجابى\",\n",
        "                        \":heart_on_fire:\": \"ايجابى\",\n",
        "                        \":victory_hand:\": \"ايجابى\",\n",
        "                        \":graduation_cap:\": \"ايجابى\",\n",
        "                        \":left-facing_fist:\": \"سلبى\",\n",
        "                        \":copyright:\" : \"ايجابى\",\n",
        "                        \":dashing_away:\": \"ايجابى\",\n",
        "                        \":index_pointing_up_light_skin_tone:\": \"ايجابى\",\n",
        "                        \":face_with_rolling_eyes:\": \"سلبى\",\n",
        "                        \":genie:\": \"ايجابى\",\n",
        "                        \":love-you_gesture:\": \"ايجابى\",\n",
        "                        \":-D⁩⁦:\": \"ايجابى\",\n",
        "                        \"-O\": \"ايجابى\",\n",
        "                        \":‑X⁩⁦:\": \"سلبى\",\n",
        "                        \":thumbs_down_medium-light_skin_tone:\": \"سلبى\",\n",
        "                        \":weary_face:\": \"سلبى\",\n",
        "                        \":balloon:\": \"ايجابى\",\n",
        "                        \":wrapped_gift:\": \"ايجابى\",\n",
        "                        \":love_letter:\": \"ايجابى\",\n",
        "                        \":face_with_medical_mask:\": \"سلبى\",\n",
        "                        \":part_alternation_mark:\": \"سلبى\",\n",
        "                        \":face_with_open_mouth:\" : \"سلبى\" ,\n",
        "                        \":backhand_index_pointing_left:\": \"ايجابى\",\n",
        "                        \":backhand_index_pointing_right:\": \"ايجابى\",\n",
        "                        \":relieved_face:\": \"سلبى\",\n",
        "                        \":crown:\": \"ايجابى\",\n",
        "                        \":confounded_face:\": \"سلبى\",\n",
        "                        \":ring:\": \"ايجابى\",\n",
        "                        \":OK_hand_medium-light_skin_tone:\": \"ايجابى\",\n",
        "                        \":middle_finger_dark_skin_tone:\": \"سلبى\",\n",
        "                        \":glowing_star:\": \"ايجابى\",\n",
        "                        \":saxophone:\": \"ايجابى\",\n",
        "                        \":upside-down_face:\": \"سلبى\",\n",
        "                        \":man_raising_hand:\": \"سلبى\",\n",
        "                        \":horse:\": \"ايجابى \",\n",
        "                        \":orange_square:\": \"ايجابى \",\n",
        "                        \":index_pointing_up:\": \" ايجابى\",\n",
        "                        \":comet:\": \"ايجابى \",\n",
        "                        \":sleepy_face:\": \"سلبى\",\n",
        "                        \":popcorn:\": \"ايجابى \",\n",
        "                        \":drooling_face:\": \"ايجابى \",\n",
        "                        \":pouting_cat:\": \"سلبى\",\n",
        "                        \":slightly_frowning_face:\": \"سلبى\",\n",
        "                        \":crying_cat:\": \"سلبى\",\n",
        "                        \":face_with_crossed-out_eyes:\": \" ايجابى\",\n",
        "                        \":flexed_biceps_light_skin_tone:\": \"ايجابى\",\n",
        "                        \":OK_hand_medium_skin_tone:\": \"ايجابى \",\n",
        "                        \":raised_hand_light_skin_tone:\": \"سلبى\",\n",
        "                        \":thumbs_down_light_skin_tone:\": \"سلبى\",\n",
        "                        \":full_moon_face:\": \"سلبى\",\n",
        "                        \":worried_face:\": \"سلبى\",\n",
        "                        \":person_gesturing_NO:\": \"سلبى\",\n",
        "                        \":sneezing_face:\" : \"سلبى\" ,\n",
        "                        \":open_hands:\" : \"ايجابى\" ,\n",
        "                        \":female_sign:\": \"ايجابى\",\n",
        "                        \":face_with_head-bandage:\": \"ايجابى\",\n",
        "                        \":candy:\": \"سلبى\",\n",
        "                        \":lollipop:\": \"سلبى\",\n",
        "                        \":ice_cream:\": \" سلبى\",\n",
        "                        \":soft_ice_cream:\": \" سلبى\",\n",
        "                        \":shortcake:\": \" سلبى\",\n",
        "                        \":cupcake:\": \" سلبى\",\n",
        "                        \":honey_pot:\": \" سلبى\",\n",
        "                        \":chocolate_bar:\": \" سلبى\",\n",
        "                        \":doughnut:\": \" سلبى\",\n",
        "                        \":cookie:\": \" سلبى\",\n",
        "                        \":clinking_beer_mugs:\": \" سلبى\",\n",
        "                        \":tumbler_glass:\": \" سلبى\",\n",
        "                        \":tropical_drink:\": \" سلبى\",\n",
        "                        \":lobster:\": \" سلبى\",\n",
        "                        \":burrito:\": \" سلبى\",\n",
        "                        \":shallow_pan_of_food:\": \" سلبى\",\n",
        "                        \":ribbon:\" : \"ايجابى\",\n",
        "                        \":weary_cat:\": \"سلبى\",\n",
        "                        \":squinting_face_with_tongue:\": \"سلبى\",\n",
        "                        \":shaved_ice:\": \"ايجابى\",\n",
        "                        \":wine_glass:\": \"ايجابى\",\n",
        "                        \":maple_leaf:\": \"ايجابى\",\n",
        "                        \":clapping_hands_light_skin_tone:\": \"ايجابى\",\n",
        "                        \":stop_sign:\": \"سلبى\",\n",
        "                        \":backhand_index_pointing_up:\": \"ايجابى\",\n",
        "                        \":waving_hand:\": \"ايجابى\",\n",
        "                        \":face_with_monocle:\": \"سلبى\",\n",
        "                        \":globe_with_meridians:\": \"ايجابى\",\n",
        "                        \":down-left_arrow:\": \"سلبى\",\n",
        "                        \":bow_and_arrow:\": \"ايجابى\",\n",
        "                        \":cocktail_glass:\": \"ايجابى\",\n",
        "                        \":beer_mug:\": \"ايجابى\",\n",
        "                        \":sake:\": \"ايجابى\",\n",
        "                        \":hot_beverage:\": \"ايجابى\",\n",
        "                        \":teacup_without_handle:\": \"ايجابى\",\n",
        "                        \":baby_bottle:\": \"ايجابى\",\n",
        "                        \":fork_and_knife:\": \"ايجابى\",\n",
        "                        \":custard:\": \"ايجابى\",\n",
        "                        \":fish_cake_with_swirl:\": \"ايجابى\",\n",
        "                        \":rice_cracker:\": \"ايجابى\",\n",
        "                        \":roasted_sweet_potato:\": \"ايجابى\",\n",
        "                        \":banana:\": \"ايجابى\",\n",
        "                        \":tangerine:\": \"ايجابى\",\n",
        "                        \":lemon:\": \"ايجابى\",\n",
        "                        \":mushroom:\": \"ايجابى\",\n",
        "                        \":tomato:\": \"ايجابى\",\n",
        "                        \":grapes:\": \"ايجابى\",\n",
        "                        \":melon:\": \"ايجابى\",\n",
        "                        \":watermelon:\": \"ايجابى\",\n",
        "                        \":pear:\": \"ايجابى\",\n",
        "                        \":peach:\": \"ايجابى\",\n",
        "                        \":strawberry:\": \"ايجابى\",\n",
        "                        \":pineapple:\": \"ايجابى\",\n",
        "                        \":wedding:\": \"ايجابى\",\n",
        "                        \":desert_island:\": \"ايجابى\",\n",
        "                        \":desert:\": \"ايجابى\",\n",
        "                        \":beach_with_umbrella:\": \"سلبى\",\n",
        "                        \":camping:\": \"سلبى\",\n",
        "                        \":Japanese_dolls:\": \"سلبى\",\n",
        "                        \":moon_viewing_ceremony:\": \"سلبى\",\n",
        "                        \":thumbs_down_medium_skin_tone:\": \"سلبى\",\n",
        "                        \":sweat_droplets:\": \"سلبى\",\n",
        "                        \":rosette:\": \"سلبى\",\n",
        "                        \":partying_face:\": \"ايجابى\",\n",
        "                        \":bug:\": \"ايجابى\",\n",
        "                        \":fish:\": \"ايجابى\",\n",
        "                        \":princess:\": \"ايجابى\",\n",
        "                        \":people_with_bunny_ears:\" : \"ايجابى\",\n",
        "                        \":party_popper:\": \"ايجابى\",\n",
        "                        \":no_mobile_phones:\": \"ايجابى\",\n",
        "                        \":bomb:\": \"سلبى\",\n",
        "                        \":skull:\": \"سلبى\",\n",
        "                        \":anger_symbol:\": \"سلبى\",\n",
        "                        \":prohibited:\": \"سلبى\",\n",
        "                        \":pig_face:\": \"سلبى\",\n",
        "                        \":pig:\": \"سلبى\",\n",
        "                        \":kitchen_knife:\": \"سلبى\",\n",
        "                        \":brown_heart:\": \"ايجابى\",\n",
        "                        \":person_pouting:\": \"ايجابى\", #0\n",
        "                        \":boy:\": \"ايجابى\", #0\n",
        "                        \":money-mouth_face:\": \"ايجابى\",\n",
        "                        \":sunflower:\": \"ايجابى\",\n",
        "                        \":trade_mark:\": \"ايجابى\",\n",
        "                        \":handshake:\": \"ايجابى\",\n",
        "                        \":litter_in_bin_sign:\": \"سلبى\",\n",
        "                        \":thumbs_down_dark_skin_tone:\": \"سلبى\",\n",
        "                        \":middle_finger_light_skin_tone:\": \"سلبى\",\n",
        "                        \":check_mark:\": \"ايجابى\",\n",
        "                        \":hot_dog:\": \"ايجابى\",\n",
        "                        \":taco:\": \"ايجابى\",\n",
        "                        \":bowl_with_spoon:\": \"ايجابى\",\n",
        "                        \":green_salad:\": \"ايجابى\",\n",
        "                        \":canned_food:\": \"ايجابى\",\n",
        "                        \":butterfly:\": \"ايجابى\",\n",
        "                        \":rainbow:\": \"ايجابى\",\n",
        "                        \":United_States:\" : \"سلبى\" ,\n",
        "                        \":person_frowning:\": \"سلبى\",\n",
        "                        \":bell_with_slash:\": \"ايجابى\",\n",
        "                        \":down_arrow:\": \"سلبى\",\n",
        "                        \":person_biking:\": \"سلبى\",\n",
        "                        \":watch:\": \"ايجابى\",\n",
        "                        \":crescent_moon:\": \"ايجابى\",\n",
        "                        \":-|:\": \"ايجابى\",\n",
        "                        \":-&&) ٪٣$♕♕♕♡&:\": \"ايجابى\",\n",
        "                        \":falafel:\": \"ايجابى\",\n",
        "                        \":bagel:\": \"ايجابى\",\n",
        "                        \":sleeping_face:\": \"ايجابى\",\n",
        "                        \":military_medal:\": \"ايجابى\",\n",
        "                        \":bird:\": \"ايجابى\",\n",
        "                        \":euro_banknote:\": \"ايجابى\",\n",
        "                        \":person_facepalming_light_skin_tone:\": \"سلبى\",\n",
        "                        \":prince:\": \"ايجابى\",\n",
        "                        \":fearful_face:\": \"سلبى\",\n",
        "                        \":cold_face:\": \"سلبى\",\n",
        "                        \":dvd:\": \"سلبى\",\n",
        "                        \":optical_disk:\": \"سلبى\",\n",
        "                        \": ـَ:\": \"ايجابى\",\n",
        "                        \":ـ⃢:\": \" ايجابي\",\n",
        "                        \":(ـ⃢ :\": \"ايجابى\",\n",
        "                        \":ـَ):\": \" ايجابي\",\n",
        "                        \":ewe:\": \"ايجابى\",\n",
        "                        \":ram:\": \"ايجابى\",\n",
        "                        \":yawning_face:\": \"سلبى\",\n",
        "                        \":white_question_mark:\": \"ايجابى\",\n",
        "                        \":croissant:\": \"ايجابى\",\n",
        "                        \":baguette_bread:\": \"ايجابى\",\n",
        "                        \":pretzel:\" : \"ايجابى\",\n",
        "                        \":large_orange_diamond:\": \"ايجابى\",\n",
        "                        \":fireworks:\": \"ايجابى\",\n",
        "                        \":diamond_suit:\": \"ايجابى\",\n",
        "                        \":spade_suit:\": \"ايجابى\",\n",
        "                        \":man_running:\": \"ايجابى\",\n",
        "                        \":woman_walking:\": \"ايجابى\",\n",
        "                        \":man_superhero:\": \"ايجابى\",\n",
        "                        \":motorcycle:\": \"ايجابى\",\n",
        "                        \":reverse_button:\": \"ايجابى\",\n",
        "                        \":play_button:\": \"سلبى\",\n",
        "                        \":Yemen:\": \"ايجابى\",\n",
        "                        \":woman_dancing_light_skin_tone:\": \"ايجابى\",\n",
        "                        \":person_taking_bath:\": \"ايجابى\",\n",
        "                        \":middle_finger:\": \"سلبى\",\n",
        "                        \":syringe:\": \"ايجابى\",\n",
        "                        \":pill:\": \"ايجابى\",\n",
        "                        \":QATAR_SHOPPING:\": \"ايجابى\",\n",
        "                        \":megaphone:\": \"ايجابى\",\n",
        "                        \":trophy:\": \"ايجابى\",\n",
        "                        \":baby_angel:\": \"ايجابى\",  #0\n",
        "                        \":person_gesturing_OK:\": \"ايجابى\",\n",
        "                        \":airplane:\": \"ايجابى\",\n",
        "                        \":frowning_face_with_open_mouth:\": \"سلبى\",\n",
        "                        \":person_bowing:\": \"سلبى\",\n",
        "                        \":ghost:\": \"سلبى\",\n",
        "                        \":chequered_flag:\": \"ايجابى\",\n",
        "                        \":Morocco:\": \"ايجابى\",\n",
        "                        \":Qatar:\" : \"ايجابى\",\n",
        "                        \":Saudi_Arabia:\": \"ايجابى\",\n",
        "                        \":Singapore:\": \"ايجابى\",\n",
        "                        \":Turkey:\": \"ايجابى\",\n",
        "                        \":Lebanon:\": \"ايجابى\",\n",
        "                        \":Indonesia:\": \"ايجابى\",\n",
        "                        \":Iraq:\": \"ايجابى\",\n",
        "                        \":Egypt:\": \"ايجابى\",\n",
        "                        \":Bahrain:\": \"ايجابى\",\n",
        "                        \":United_Arab_Emirates:\": \"ايجابى\",\n",
        "                        \":smiling_face_with_tear:\": \"سلبى\",\n",
        "                        \":telephone:\": \"ايجابى\",\n",
        "                        \":rabbit_face:\": \"ايجابى\",\n",
        "                        \":panda:\": \"ايجابى\",\n",
        "                        \":snake:\": \"ايجابى\",\n",
        "                        \":man_facepalming:\": \"سلبى\",\n",
        "                        \":octopus:\": \"ايجابى\",\n",
        "                        \":grinning_cat:\": \"ايجابى\",\n",
        "                        \":thumbs_up_dark_skin_tone:\": \"ايجابى\",\n",
        "                        \":musical_score:\": \"ايجابى\",\n",
        "                        \":jack-o-lantern:\": \"ايجابى\",\n",
        "                        \":warning:\": \"سلبى\",\n",
        "                        \":globe_showing_Asia-Australia:\": \"ايجابى\",\n",
        "                        \":alien:\": \"سلبى\",\n",
        "                        \":TOP_arrow:\": \"ايجابى\",\n",
        "                        \":alembic:\": \"ايجابى\", #0\n",
        "                        \":Virgo:\": \"ايجابى\", #0\n",
        "                        \":anxious_face_with_sweat:\": \"سلبى\",\n",
        "                        \":milky_way:\" : \"ايجابى\",\n",
        "                        \":love-you_gesture_light_skin_tone:\": \"ايجابى\",\n",
        "                        \":cat_with_wry_smile:\": \"سلبى\",\n",
        "                        \":blossom:\": \"ايجابى\",\n",
        "                        \":United_Kingdom:\": \"ايجابى\",\n",
        "                        \":club_suit:\": \"سلبى\",\n",
        "                        \":raised_hand_medium_skin_tone:\": \"ايجابى\", #0\n",
        "                        \":victory_hand_light_skin_tone:\": \"ايجابى\",\n",
        "                        \":dove:\": \"سلبى\",\n",
        "                        \":fork_and_knife_with_plate:\": \"ايجابى\",\n",
        "                        \":umbrella_with_rain_drops:\": \"ايجابى\",\n",
        "                        \":call_me_hand_medium-light_skin_tone:\": \"ايجابى\",\n",
        "                        \":palms_up_together_light_skin_tone:\": \"ايجابى\",\n",
        "                        \":):\": \"ايجابى\",\n",
        "                        \":angry_face_with_horns:\": \"سلبى\",\n",
        "                        \":people_hugging:\": \"ايجابى\",\n",
        "                        \":seedling:\": \"ايجابى\",\n",
        "                        \":mosque:\": \"ايجابى\",\n",
        "                        \":houses:\": \"ايجابى\",\n",
        "                        \":building_construction:\": \"ايجابى\",\n",
        "                        \":classical_building:\": \"ايجابى\",\n",
        "                        \":kaaba:\": \"ايجابى\",\n",
        "                        \":man_getting_massage_light_skin_tone:\": \"سلبى\",\n",
        "                        \":clinking_glasses:\": \"ايجابى\",\n",
        "                        \":middle_finger_medium_skin_tone:\": \"سلبى\",\n",
        "                        \":palms_up_together:\": \"ايجابى\",\n",
        "                        \":folded_hands_light_skin_tone:\" : \"ايجابى\" ,\n",
        "                        \":baby:\": \"سلبى\",\n",
        "                        \":fox:\": \"سلبى\",\n",
        "                        \":oncoming_fist_light_skin_tone:\": \"سلبى\",\n",
        "                        \":woman_facepalming:\": \"سلبى\",\n",
        "                        \":dress:\": \"ايجابى\",\n",
        "                        \":t-shirt:\": \"ايجابى\",\n",
        "                        \":high-heeled_shoe:\": \"ايجابى\",\n",
        "                        \":construction:\": \"ايجابى\",\n",
        "                        \":confetti_ball:\": \"ايجابى\",\n",
        "                        \":toilet:\": \"سلبى\",\n",
        "                        \":speaking_head:\": \"ايجابى\",\n",
        "                        \":skull_and_crossbones:\": \"سلبى\",\n",
        "                        \":office_building:\": \"ايجابى\",\n",
        "                        \":FREE_button:\": \"ايجابى\",\n",
        "                        \":woozy_face:\": \"سلبى\",\n",
        "                        \":tanabata_tree:\": \"ايجابى\",\n",
        "                        \":person_raising_hand:\": \"ايجابى\",\n",
        "                        \":backhand_index_pointing_down:\": \"سلبى\",\n",
        "                        \":pinching_hand:\": \"ايجابى\",\n",
        "                        \":hand_with_fingers_splayed:\": \"ايجابى\",\n",
        "                        \":bicycle:\": \"ايجابى\",\n",
        "                        \":motor_scooter:\": \"ايجابى\",\n",
        "                        \":birthday_cake:\": \"ايجابى\"  ,\n",
        "                        \": QATAR_SHOPPING :\" : \"ايجابى \" ,\n",
        "                        \":Monaco:\": \"ايجابى \",\n",
        "                        \":guard:\": \"ايجابى \",\n",
        "                        \":exploding_head:\": \"ايجابى \",\n",
        "                        \":camera:\": \"ايجابى \",\n",
        "                        \":television:\": \"ايجابى \",\n",
        "                        \":person_rowing_boat:\": \"ايجابى \",\n",
        "                        \":heavy_dollar_sign:\": \"ايجابى \",\n",
        "                        \":face_with_thermometer:\": \"سلبى \",\n",
        "                        \":goblin:\": \"سلبى \",\n",
        "                        \":robot:\": \"سلبى \",\n",
        "                        \":alien_monster:\": \"سلبى \",\n",
        "                        \":'(⁩:\": \"سلبى \",\n",
        "                        \":person_with_veil:\": \"ايجابى \",\n",
        "                        \":shower:\": \"ايجابى \",\n",
        "                        \":cow:\": \"سلبى \",\n",
        "                        \":musical_notes:\": \"ايجابى \",\n",
        "                        \":man’s_shoe:\": \"سلبى \",\n",
        "                        \":gloves:\": \"ايجابى \",\n",
        "                        \":face_with_spiral_eyes:\": \"سلبى \",\n",
        "  }\n",
        "  # Convert emojis to their text representations\n",
        "  text_with_emoji_converted = emoji.demojize(text)\n",
        "\n",
        "  # Extract emojis using regular expression\n",
        "  emojis = re.findall(r\":[^:]+:\", text_with_emoji_converted)\n",
        "  for en_emojis, ar_emojis in emoji_translations.items():\n",
        "    text_with_emoji_converted = text_with_emoji_converted.replace(en_emojis,ar_emojis)\n",
        "  return text_with_emoji_converted\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-6bFSglUo3j"
      },
      "outputs": [],
      "source": [
        "def detect_language(text):\n",
        "    for char in text:\n",
        "      if 'a'<=char<='z' or 'A'<=char<='Z':\n",
        "        return 'english'\n",
        "      elif 'أ'<=char<='ي' or 'ا'<=char<='ى':\n",
        "        return 'arabic'\n",
        "      else:\n",
        "        return 'unknown'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BktSWsECUsYI"
      },
      "outputs": [],
      "source": [
        "def english_to_arabic(text):\n",
        "  negative_english_words = ['bad','sad','hate','horrible']\n",
        "  positive_english_words = ['good','nice','amazing','love','great']\n",
        "  english_sentences = \"\"\n",
        "  cnt = 0\n",
        "  for word in text.split():\n",
        "        detected_language = detect_language(word)\n",
        "        cnt +=1\n",
        "        if detected_language == 'english':\n",
        "            english_sentences = english_sentences + \" \" +word.lower()\n",
        "            if len(word)==1:\n",
        "              text = text[cnt:]\n",
        "            else:\n",
        "              text = text.replace(word,'')\n",
        "        else:\n",
        "            continue\n",
        "  if english_sentences != \" \":\n",
        "    for i in english_sentences.split():\n",
        "      if i in negative_english_words:\n",
        "        text = text + \" \" +'سئ'\n",
        "      elif i in positive_english_words:\n",
        "        text = text + \" \"+ 'جيد'\n",
        "      else:\n",
        "        text = text\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFWZizcU658B"
      },
      "outputs": [],
      "source": [
        "def augment_text(df):\n",
        "    augmenter = naw.RandomWordAug(action='delete', name='RandomWord_Aug', aug_min=1, aug_max=10, aug_p=0.3, stopwords=None,\n",
        "                        target_words=None, tokenizer=None, reverse_tokenizer=None, stopwords_regex=None, verbose=0)\n",
        "    # augmenter = naw.SynonymAug(aug_src='wordnet', model_path=None, name='Synonym_Aug', aug_min=1, aug_max=10, aug_p=0.3, lang='eng',\n",
        "    #                  stopwords=None, tokenizer=None, reverse_tokenizer=None, stopwords_regex=None, force_reload=False,\n",
        "    #                  verbose=0)\n",
        "\n",
        "    # augmenter = naw.AntonymAug(name='Antonym_Aug', aug_min=1, aug_max=10, aug_p=0.3, lang='eng', stopwords=None, tokenizer=None,\n",
        "    #                  reverse_tokenizer=None, stopwords_regex=None, verbose=0)\n",
        "\n",
        "    TOPK=100\n",
        "    ACT = 'insert'\n",
        "\n",
        "    augmenter = naw.ContextualWordEmbsAug(\n",
        "    model_path='distilbert-base-uncased',\n",
        "    action=ACT, top_k=TOPK)\n",
        "    new_text=[]\n",
        "    df_empty = pd.DataFrame(columns=['review_description', 'rating'])\n",
        "    ##selecting the minority class samples\n",
        "    df_n=df[df.rating==0].reset_index(drop=True)\n",
        "    ## data augmentation loop\n",
        "    for i in tqdm(np.random.randint(0,len(df_n),5000)):\n",
        "\n",
        "            text = df_n.iloc[i]['review_description']\n",
        "            augmented_text = [augmenter.augment(text)]\n",
        "            data = {'review_description': augmented_text, 'rating': 0}\n",
        "            df_another = pd.DataFrame(data)\n",
        "            frames = [df_empty, df_another]\n",
        "            df_empty = pd.concat(frames, ignore_index=True)\n",
        "            #new_text.append(augmented_text)\n",
        "\n",
        "    ## dataframe\n",
        "    #new=pd.DataFrame({'review_description':new_text,'rating':0})\n",
        "    ha = [df, df_empty]\n",
        "    new = pd.concat(ha,ignore_index=True)\n",
        "    return new"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textaugment"
      ],
      "metadata": {
        "id": "NDEkKp0ObQ4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uRPHsVEgE9J"
      },
      "outputs": [],
      "source": [
        "\n",
        "from textaugment import Wordnet\n",
        "from textaugment import Translate\n",
        "from textaugment import EDA\n",
        "from nltk import ngrams\n",
        "def data_augmentation_fast(data):\n",
        "  # Initialize the augmenter\n",
        "  #augmenter = WordNetAugmenter()\n",
        "  t = EDA()\n",
        "\n",
        "  # Subset the minority class data\n",
        "  minority_data = data[data['rating'] == 0]['review_description']\n",
        "\n",
        "  # Extract the initial 1500 rows from minority_data\n",
        "  initial_data = minority_data[:1507]\n",
        "\n",
        "  # Augment the initial data to reach a total of 5500 rows\n",
        "  df_augmented = pd.DataFrame({'review_description': initial_data, 'rating': 0})\n",
        "  while len(df_augmented) < 6000:\n",
        "      remaining_augment = 6000 - len(df_augmented)\n",
        "      augment_texts = []\n",
        "      for text in initial_data:\n",
        "          if len(augment_texts) >= remaining_augment:\n",
        "              break  # Stop when reaching the remaining required texts\n",
        "          augmented_text = t.synonym_replacement(text)\n",
        "          #augmented_text = augmenter.augment(text)\n",
        "          augment_texts.extend(augmented_text)\n",
        "      initial_data = augment_texts\n",
        "      df_augmented = pd.concat([df_augmented, pd.DataFrame({'review_description': augment_texts, 'rating': 0})])\n",
        "  df_augmented = pd.concat([data, df_augmented])\n",
        "  return df_augmented"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tTkYxHVYezv"
      },
      "outputs": [],
      "source": [
        "def data_augmentation(data):\n",
        "  sentences = data['review_description'].values\n",
        "  labels = data['rating'].values\n",
        "  augmenter = naw.ContextualWordEmbsAug(model_path='bert-base-multilingual-uncased', action='insert')\n",
        "  subset_data = data[data['rating'] == 0].sample(frac=0.1)\n",
        "  augmented_texts = augmenter.augment(subset_data['review_description'], n=1)  # Generating 100 augmented texts\n",
        "\n",
        "  # Concatenate the original and augmented texts\n",
        "  df_augmented = pd.concat([data, pd.DataFrame({'review_description': augmented_texts, 'rating': 0})])\n",
        "  return df_augmented"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKCNIMlBj56V"
      },
      "outputs": [],
      "source": [
        "def preprocessing(data):\n",
        "  sentences = data['review_description'].values\n",
        "  labels = data['rating'].values\n",
        "  preprocessed_list=[]\n",
        "  df_empty = pd.DataFrame(columns=['review_description', 'rating'])\n",
        "  for i in tqdm(data.index,desc='processing rows'):\n",
        "    removed_emojis = emojis_converter(sentences[i])\n",
        "    convert_to_arabic = english_to_arabic(removed_emojis)\n",
        "    removed_punctuation = remove_punctuation(convert_to_arabic)\n",
        "    word_tokens = word_tokenize(removed_punctuation)\n",
        "    removed_sw = remove_stop_words(word_tokens)\n",
        "    stemming = [arabic_lemmatizer(removed_sw)]\n",
        "    #preprocessed_list = np.append(preprocessed_list,stemming)\n",
        "    # Adding rows from df_another to df_empty\n",
        "    data = {'review_description': stemming, 'rating': labels[i]}\n",
        "    df_another = pd.DataFrame(data)\n",
        "    frames = [df_empty, df_another]\n",
        "    df_empty = pd.concat(frames, ignore_index=True)\n",
        "    #df_empty = pd.concat({'review_description':stemming, 'rating': labels[i]}, ignore_index=True)\n",
        "  return df_empty\n",
        "def preprocessing_test(data):\n",
        "  sentences = data['review_description'].values\n",
        "  ids = data['ID'].values\n",
        "  preprocessed_list=[]\n",
        "  df_empty = pd.DataFrame(columns=['review_description', 'ID'])\n",
        "  for i in tqdm(data.index,desc='processing rows'):\n",
        "    removed_emojis = emojis_converter(sentences[i])\n",
        "    convert_to_arabic = english_to_arabic(removed_emojis)\n",
        "    removed_punctuation = remove_punctuation(convert_to_arabic)\n",
        "    word_tokens = word_tokenize(removed_punctuation)\n",
        "    removed_sw = remove_stop_words(word_tokens)\n",
        "    stemming = [arabic_lemmatizer(removed_sw)]\n",
        "    #preprocessed_list = np.append(preprocessed_list,stemming)\n",
        "    # Adding rows from df_another to df_empty\n",
        "    data = {'review_description': stemming, 'ID': ids[i]}\n",
        "    df_another = pd.DataFrame(data)\n",
        "    frames = [df_empty, df_another]\n",
        "    df_empty = pd.concat(frames, ignore_index=True)\n",
        "    #df_empty = pd.concat({'review_description':stemming, 'rating': labels[i]}, ignore_index=True)\n",
        "  return df_empty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "za9LwEZPk1oi"
      },
      "outputs": [],
      "source": [
        "data = pd.read_excel('sample_data/train.xlsx')\n",
        "df_before_aug = preprocessing(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_before_aug"
      ],
      "metadata": {
        "id": "dWf85WuYUASP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('sample_data/train.xlsx')\n",
        "augmented_data=data_augmentation_fast(data)\n",
        "df_after_aug = preprocessing(augmented_data)\n",
        "test_df = pd.read_csv('sample_data/test _no_label.csv')\n",
        "preprocessed_test = preprocessing_test(test_df)"
      ],
      "metadata": {
        "id": "H92gDphOat5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_after_aug"
      ],
      "metadata": {
        "id": "2ykzGTTJa9Qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "def lstm_model(df):\n",
        "    sentences = df['review_description'].values\n",
        "    labels = df['rating'].values\n",
        "    # Convert text to sequences\n",
        "\n",
        "    # Fit the tokenizer on the tokens\n",
        "    tokenizer.fit_on_texts(sentences)\n",
        "    sequences = tokenizer.texts_to_sequences(sentences)\n",
        "    #sequences = Tokenizer.texts_to_sequences(i)\n",
        "\n",
        "    # Padding\n",
        "     #Adjust based on your desired sequence length\n",
        "    padded_sequences = pad_sequences(sequences, maxlen=16, padding='post', truncating='post')\n",
        "    # # Convert labels to one-hot encoding\n",
        "    one_hot_labels = pd.get_dummies(labels).values\n",
        "    # Split the data into training and validation sets\n",
        "    #X_train, X_test, y_train, y_test = train_test_split(padded_sequences, one_hot_labels, test_size=0.2, random_state=42)\n",
        "    #Build the LSTM model\n",
        "    model = Sequential()\n",
        "    vocab_size=len(tokenizer.word_index) + 1\n",
        "    model.add(Embedding(input_dim=vocab_size, output_dim=100))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(LSTM(160))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    # Train the model\n",
        "    epochs =4   # Adjust based on your training preferences\n",
        "    batch_size = 32  # Adjust based on your available resources\n",
        "    model.fit(padded_sequences, one_hot_labels, validation_split=0.1, epochs=epochs, batch_size=batch_size)\n",
        "    # Save the trained model\n",
        "\n",
        "    #loss, accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "    model.save('sample_data/lstm_model_n.h5')\n",
        "from keras.models import load_model\n",
        "def lstm_model_test(df):\n",
        "    sentences = df['review_description'].values\n",
        "    ids = df['ID'].values\n",
        "    # Convert text to sequences\n",
        "\n",
        "    # Fit the tokenizer on the tokens\n",
        "\n",
        "    sequences = tokenizer.texts_to_sequences(sentences)\n",
        "    #sequences = Tokenizer.texts_to_sequences(i)\n",
        "    print(sequences)\n",
        "    # Padding\n",
        "    # input_length = 10  #Adjust based on your desired sequence length\n",
        "    padded_sequences = pad_sequences(sequences, maxlen=16, padding='post', truncating='post')\n",
        "    # Load the trained model\n",
        "    loaded_model = load_model('sample_data/lstm_model_n.h5')  # Replace 'path_to_your_trained_model.h5' with the actual path\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = loaded_model.predict(padded_sequences)\n",
        "\n",
        "    # Assuming the predictions are probabilities, you might want to convert them back to ratings\n",
        "    # For example, let's assume the highest probability corresponds to the predicted rating\n",
        "    # predicted_ratings = [int(pd.Series(p).idxmax()) + 1 for p in predictions]  # Adding 1 because the ratings might start from 1 instead of 0\n",
        "\n",
        "    pred = np.argmax(predictions, axis=1) -1\n",
        "    #y_pred_classes = y_pred.argmax(axis=1) - 1  # Assuming classes are originally 0, 1, 2\n",
        "\n",
        "\n",
        "    ans= pd.DataFrame({'ID': ids,  # Replace with your actual column names\n",
        "                              'rating': pred})\n",
        "\n",
        "    ans.to_csv('sample_data/predicted_results_half_pre.csv', index=False)"
      ],
      "metadata": {
        "id": "T6KTMNcqk-m6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import SimpleRNN, Embedding,Conv1D,GlobalMaxPooling1D,Dense,Dropout\n",
        "from keras.optimizers import Adam\n",
        "def rnn_model(df):\n",
        "    sentences = df['review_description'].values\n",
        "    labels = df['rating'].values\n",
        "    # Convert text to sequences\n",
        "\n",
        "    # Fit the tokenizer on the tokens\n",
        "    tokenizer.fit_on_texts(sentences)\n",
        "    sequences = tokenizer.texts_to_sequences(sentences)\n",
        "    #sequences = Tokenizer.texts_to_sequences(i)\n",
        "\n",
        "    # Padding\n",
        "     #Adjust based on your desired sequence length\n",
        "    padded_sequences = pad_sequences(sequences, maxlen=16, padding='post', truncating='post')\n",
        "    # # Convert labels to one-hot encoding\n",
        "    one_hot_labels = pd.get_dummies(labels).values\n",
        "    # Split the data into training and validation sets\n",
        "    #X_train, X_test, y_train, y_test = train_test_split(padded_sequences, one_hot_labels, test_size=0.2, random_state=42)\n",
        "    #Build the LSTM model\n",
        "    model = Sequential()\n",
        "    vocab_size=len(tokenizer.word_index) + 1\n",
        "    model.add(Embedding(input_dim=vocab_size, output_dim=100))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(SimpleRNN(50))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    # Train the model\n",
        "    epochs =4   # Adjust based on your training preferences\n",
        "    batch_size = 32  # Adjust based on your available resources\n",
        "    model.fit(padded_sequences, one_hot_labels, validation_split=0.1, epochs=epochs, batch_size=batch_size)\n",
        "    # Save the trained model\n",
        "\n",
        "    #loss, accuracy = model.evaluate(X_test, y_test)\n"
      ],
      "metadata": {
        "id": "3FBOyOXxdaNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model"
      ],
      "metadata": {
        "id": "mIVW9alreLTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(preprocessed_test)"
      ],
      "metadata": {
        "id": "oApV_AvyyCpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model(df_after_aug)"
      ],
      "metadata": {
        "id": "JefchkgNnOzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model_test(preprocessed_test)"
      ],
      "metadata": {
        "id": "DSCQOhSDxe07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zdhCwZ6nMRUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abdallah = pd.read_excel('sample_data/Book.xlsx')\n",
        "nancy = pd.read_excel('sample_data/nancy_nn.xlsx')\n",
        "a=abdallah[\"rating\"].values.tolist()\n",
        "n=nancy['label'].values.tolist()\n",
        "c=0\n",
        "diff=[]\n",
        "for i in range(len(a)):\n",
        "  if a[i]==n[i]:\n",
        "    c+=1\n",
        "\n",
        "print(c)\n"
      ],
      "metadata": {
        "id": "rJ4RpzNG7kQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, GlobalAveragePooling1D, Dense, Dropout, LayerNormalization, MultiHeadAttention\n",
        "from tensorflow.keras.models import Model\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "tokenizer = Tokenizer()\n",
        "def trans():\n",
        "    # Function to create a single transformer block\n",
        "    def transformer_block(inputs, embed_dim, num_heads, ff_dim, rate=0.01):\n",
        "      attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(inputs, inputs)\n",
        "      attn_output = Dropout(rate)(attn_output)\n",
        "      out1 = LayerNormalization(epsilon=1e-6)(inputs + attn_output)\n",
        "\n",
        "      ffn_output = Dense(ff_dim, activation='relu')(out1)\n",
        "      ffn_output = Dropout(rate)(ffn_output)\n",
        "      return LayerNormalization()(ffn_output)\n",
        "\n",
        "    # Function to build the transformer model\n",
        "    def build_transformer_model(max_len, vocab_size, embed_dim, num_heads, ff_dim, num_classes):\n",
        "        inputs = Input(shape=(max_len,))\n",
        "        embedding_layer = Embedding(input_dim=vocab_size, output_dim=embed_dim)(inputs)\n",
        "\n",
        "        transformer_blocks1 = transformer_block(embedding_layer, embed_dim, num_heads, ff_dim)\n",
        "\n",
        "        gap_layer = GlobalAveragePooling1D()(transformer_blocks1)\n",
        "        output_layer = Dense(num_classes, activation='softmax')(gap_layer)\n",
        "\n",
        "        model = Model(inputs=inputs, outputs=output_layer)\n",
        "        return model\n",
        "\n",
        "    # Set hyperparameters\n",
        "    max_len = 100\n",
        "    vocab_size = len(tokenizer.word_index) + 1\n",
        "    embed_dim = 256\n",
        "    num_heads = 10\n",
        "    ff_dim = 256\n",
        "    num_classes = 3\n",
        "\n",
        "    # Instantiate and compile the model\n",
        "    model = build_transformer_model(max_len, vocab_size, embed_dim, num_heads, ff_dim, num_classes)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Display the model summary\n",
        "    model.summary()\n",
        "\n",
        "    df = pd.read_excel('sample_data/train.xlsx')\n",
        "    sentences = df['review_description'].values\n",
        "    labels = df['rating'].values\n",
        "\n",
        "    # Instantiate and fit the tokenizer\n",
        "\n",
        "    tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "    # Convert texts to sequences\n",
        "    sequences = tokenizer.texts_to_sequences(sentences)\n",
        "\n",
        "    # Padding\n",
        "    padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "    # Convert labels to one-hot encoding\n",
        "    one_hot_labels = pd.get_dummies(labels).values\n",
        "\n",
        "    x_train,x_test,y_train,y_test=train_test_split(padded_sequences,one_hot_labels,test_size=0.2,random_state=42)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(x_train, y_train, validation_split=0.1, epochs=5, batch_size=32)\n",
        "    model.save('sample_data/TransV05.h5')\n",
        "\n",
        "    # Uncomment if you want to evaluate the model on the test set\n",
        "    test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "    print(f'Test Accuracy: {test_acc}')\n",
        "\n",
        "\n",
        "\n",
        "def test_trans():\n",
        "  import pandas as pd\n",
        "  from tensorflow.keras.models import load_model\n",
        "  from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "  from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "  filename = 'sample_data/TransV05.h5'\n",
        "\n",
        "  # Load the Keras model\n",
        "  loaded_model = load_model(filename)\n",
        "\n",
        "  # Load your test data\n",
        "  df = preprocessed_test\n",
        "\n",
        "  sentences = df['review_description'].values\n",
        "\n",
        "  # Tokenize the text data\n",
        "\n",
        "  vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "  # Convert text to sequences\n",
        "  sequences = tokenizer.texts_to_sequences(sentences)\n",
        "\n",
        "  # Pad sequences to a fixed length\n",
        "  max_len = 100\n",
        "  padded_sequences = pad_sequences(sequences, maxlen=100, padding='post')\n",
        "  ids = df['ID'].values\n",
        "\n",
        "  predictions = loaded_model.predict(padded_sequences)\n",
        "\n",
        "    # Assuming the predictions are probabilities, you might want to convert them back to ratings\n",
        "    # For example, let's assume the highest probability corresponds to the predicted rating\n",
        "    # predicted_ratings = [int(pd.Series(p).idxmax()) + 1 for p in predictions]  # Adding 1 because the ratings might start from 1 instead of 0\n",
        "\n",
        "  pred = np.argmax(predictions, axis=1) -1\n",
        "  #y_pred_classes = y_pred.argmax(axis=1) - 1  # Assuming classes are originally 0, 1, 2\n",
        "\n",
        "\n",
        "  ans= pd.DataFrame({'ID': ids,  # Replace with your actual column names\n",
        "                            'rating': pred})\n",
        "\n",
        "  ans.to_csv('sample_data/predicted_results_half_pre.csv', index=False)"
      ],
      "metadata": {
        "id": "Yz4GaE7uLZmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trans()"
      ],
      "metadata": {
        "id": "FdGcG66mO0Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_trans()"
      ],
      "metadata": {
        "id": "oaWvvQJ7O0bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing_test(data):\n",
        "  sentences = data['review_description'].values\n",
        "  ids = data['ID'].values\n",
        "  preprocessed_list=[]\n",
        "  df_empty = pd.DataFrame(columns=['review_description', 'ID'])\n",
        "  for i in tqdm(data.index,desc='processing rows'):\n",
        "    removed_emojis = emojis_converter(sentences[i])\n",
        "    convert_to_arabic = english_to_arabic(removed_emojis)\n",
        "    removed_punctuation = remove_punctuation(convert_to_arabic)\n",
        "    word_tokens = word_tokenize(removed_punctuation)\n",
        "    removed_sw = remove_stop_words(word_tokens)\n",
        "    stemming = [arabic_stemmer(removed_sw)]\n",
        "    #preprocessed_list = np.append(preprocessed_list,stemming)\n",
        "    # Adding rows from df_another to df_empty\n",
        "    data = {'review_description': stemming, 'ID': ids[i]}\n",
        "    df_another = pd.DataFrame(data)\n",
        "    frames = [df_empty, df_another]\n",
        "    df_empty = pd.concat(frames, ignore_index=True)\n",
        "    #df_empty = pd.concat({'review_description':stemming, 'rating': labels[i]}, ignore_index=True)\n",
        "  return df_empty"
      ],
      "metadata": {
        "id": "bOngdmiW8eCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('sample_data/test _no_label.csv')\n",
        "preprocessed_test = preprocessing_test(test_df)"
      ],
      "metadata": {
        "id": "skYeXUea_qS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_test"
      ],
      "metadata": {
        "id": "mzReQ2sy_1qH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "def lstm_model_test(df):\n",
        "    sentences = df['review_description'].values\n",
        "    ids = df['ID'].values\n",
        "    # Convert text to sequences\n",
        "\n",
        "    # Fit the tokenizer on the tokens\n",
        "    tokenizer.fit_on_texts(sentences)\n",
        "    sequences = tokenizer.texts_to_sequences(sentences)\n",
        "    #sequences = Tokenizer.texts_to_sequences(i)\n",
        "    print(sequences)\n",
        "    # Padding\n",
        "    input_length = 10  #Adjust based on your desired sequence length\n",
        "    padded_sequences = pad_sequences(sequences, maxlen=15, padding='post', truncating='post')\n",
        "    # Load the trained model\n",
        "    loaded_model = load_model('sample_data/lstm_model_n.h5')  # Replace 'path_to_your_trained_model.h5' with the actual path\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = loaded_model.predict(padded_sequences)\n",
        "\n",
        "    # Assuming the predictions are probabilities, you might want to convert them back to ratings\n",
        "    # For example, let's assume the highest probability corresponds to the predicted rating\n",
        "    # predicted_ratings = [int(pd.Series(p).idxmax()) + 1 for p in predictions]  # Adding 1 because the ratings might start from 1 instead of 0\n",
        "\n",
        "    pred = np.argmax(predictions, axis=1) -1\n",
        "    #y_pred_classes = y_pred.argmax(axis=1) - 1  # Assuming classes are originally 0, 1, 2\n",
        "\n",
        "\n",
        "    ans= pd.DataFrame({'ID': ids,  # Replace with your actual column names\n",
        "                              'rating': pred})\n",
        "\n",
        "    ans.to_csv('sample_data/predicted_results_half_pre.csv', index=False)"
      ],
      "metadata": {
        "id": "hZ4q944bp4AI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model_test(preprocessed_test)"
      ],
      "metadata": {
        "id": "_thwoKzRtOZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "def transformer(df_after_aug):\n",
        "    sentences = df_after_aug['review_description'].values\n",
        "    labels = df_after_aug['rating'].values\n",
        "    t = Tokenizer()\n",
        "    #encoding\n",
        "    # Fit the tokenizer on the tokens\n",
        "    t.fit_on_texts(sentences)\n",
        "    seq = t.texts_to_sequences(sentences)\n",
        "\n",
        "    # Word2Vec model\n",
        "    embedding_dim = 100  # You can adjust this dimension based on your needs\n",
        "\n",
        "    word2vec_model = Word2Vec(sentences, vector_size=embedding_dim, window=5, min_count=1, workers=4)\n",
        "\n",
        "    # Get the vocabulary from the tokenizer\n",
        "    vocabulary_size = len(t.word_index) + 1\n",
        "\n",
        "    # Create an embedding matrix\n",
        "    embedding_matrix = np.zeros((vocabulary_size, embedding_dim))\n",
        "    for word, i in t.word_index.items():\n",
        "        if word in word2vec_model.wv:\n",
        "            embedding_matrix[i] = word2vec_model.wv[word]\n",
        "\n",
        "    # Now, embedding_matrix can be used as weights in an Embedding layer in your Keras model\n",
        "\n",
        "    print(seq)\n",
        "    #print(\"=================================================\")\n"
      ],
      "metadata": {
        "id": "hUSczyrwGKzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "def Transformer_model(df):\n",
        "\n",
        "  # Load pre-trained embeddings (replace 'path_to_glove_file.txt' with your file)\n",
        "  path_to_embeddings = r'D:\\4th.fisrtterm\\New folder\\vectors.txt'\n",
        "  word_vectors = KeyedVectors.load_word2vec_format(path_to_embeddings, binary=False)\n",
        "  print(word_vectors)\n"
      ],
      "metadata": {
        "id": "A6R4Lb62v_LX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Transformer_model(df_after_aug)"
      ],
      "metadata": {
        "id": "ihGd5qUu7nms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer(df_after_aug)"
      ],
      "metadata": {
        "id": "YnLeaML1-LiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping,LearningRateScheduler\n",
        "\n",
        "\n",
        "def transformer_classification_model(max_seq_length, vocab_size, num_heads=8, ff_dim=32, num_blocks=6, dropout_rate=0.1):\n",
        "\n",
        "    inputs = Input(shape=(max_seq_length,))\n",
        "\n",
        "    embedding_layer = Embedding(input_dim=vocab_size, output_dim=128)(inputs)\n",
        "\n",
        "    x = embedding_layer\n",
        "    for _ in range(num_blocks):\n",
        "        x = transformer_block(x, max_seq_length, num_heads, ff_dim, dropout_rate)\n",
        "\n",
        "    x = GlobalAveragePooling1D()(x)\n",
        "\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    outputs = Dense(3, activation='softmax')(x)\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "def transformer_block(x, max_seq_length, num_heads, ff_dim, dropout_rate=0.1):\n",
        "    # Multi-Head Self Attention\n",
        "    multi_head_attention = tf.keras.layers.MultiHeadAttention(\n",
        "        num_heads=num_heads, key_dim=256, dropout=dropout_rate\n",
        "    )(x, x)\n",
        "\n",
        "    # Add & Norm\n",
        "    x = tf.keras.layers.Add()([x, multi_head_attention])\n",
        "    x = tf.keras.layers.LayerNormalization()(x)\n",
        "\n",
        "    # Feed Forward Part\n",
        "    ff = tf.keras.layers.Conv1D(filters=ff_dim, kernel_size=1, activation='relu')(x)\n",
        "    ff = tf.keras.layers.Dropout(dropout_rate)(ff)\n",
        "    ff = tf.keras.layers.Conv1D(filters=128, kernel_size=1)(ff)\n",
        "\n",
        "    # Add & Norm\n",
        "    x = tf.keras.layers.Add()([x, ff])\n",
        "    x = tf.keras.layers.LayerNormalization()(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "max_seq_length = 100\n",
        "vocab_size = 10000\n",
        "num_heads = 7\n",
        "ff_dim = 20\n",
        "num_blocks = 3\n",
        "dropout_rate = 0.1\n",
        "\n",
        "model = transformer_classification_model(max_seq_length, vocab_size, num_heads, ff_dim, num_blocks, dropout_rate)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "def lr_schedule(epoch,lr):\n",
        "  return lr*0.9**epoch\n",
        "\n",
        "lr_scheduler=LearningRateScheduler(lr_schedule)\n",
        "h=model.fit(X_train_pad3, y_train_with_imbalnce_with_3_classes, validation_split=0.2, epochs=15, batch_size=32, callbacks=[early_stopping,lr_scheduler])\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test Accuracy: {test_acc}')\n",
        "test_function(model)"
      ],
      "metadata": {
        "id": "PWmf9hntT3ZH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}